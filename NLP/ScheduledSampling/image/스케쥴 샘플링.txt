구글 Quoc Le
Bow 문장의 순서를 놓침 
RNN은 순서 정보를 포함
S2S은 Many to Many로 만들었다.
예측이 잘 안됐다. 그래서 다시 RNN의 입력으로 사용 했다.


Greedy Search : 다음 단어를 가장 최고의 확률을 가지는 것으로 예측을 할것
Beam Search : n개 예측 후 조합 첫번째 예측dl 나쁘면 이후 다 망침 이를 해결하기 위한 알고리즘이
Scheduled Sampling 이다.


https://classroom.udacity.com/courses/ud730/lessons/6378983156/concepts/63733319420923

분명히 추론 단계에서 모델의 입력은 학습 단계의 입력과 다르며 모델이 실제 출력이 무엇인지 모르기 때문에 t-1에서 결과가 나 빠지면 모델은이 나쁜 결과 만 예측할 수 있습니다 산출물의 순간에 이르면 상태 공간에서 더 멀리 나아갈 가능성이있다. 결과는 점점 악화되고있다.

추론 단계에서 trian 단계와 동일한 모델을 수행 할 수 없다면 trian 단계 모델은 추론 단계와 더 비슷합니다. 간단히 말해, \ (y_ {t-1} \)을 입력 할 확률은 기차 단계에서 실제 출력 값을 사용하고 확률의 나머지 절반은 추론 단계의 모델 생성 값을 사용합니다.

다이어그램의 각 순간에 샘플링 된 \ (y_ {t-2} \) 또는 true \ (y_ {t-2} \)를 사용하는 것과 같습니다. 분명히이 \ (\ epsilon_i \)는 1이며, 이전 훈련과 동일합니다. 0 일 때, 모델은 추론 단계와 정확히 같습니다. 직관적으로 조기 교육에서 $ \ epsilon_i $는 더 커야합니다. 모형을 작성하기위한 실제 값에 대해 자세히 알아 보려면 \ (\ epsilon_i \)가 모델을 추론 단계와 유사하게 만들기 때문에 훈련이 끝날 때 작아야합니다 . 그러므로 저자는 세 가지 부패 전략을 제안한다.

 일정 샘플링 접근법의 그림,
동전을 사용할 때마다 동전을 뒤집어서 동전을 사용하기로 결정합니다.
true의 이전의 토큰 또는 모델 자체로부터 샘플 된 토큰.